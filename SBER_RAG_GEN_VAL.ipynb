{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6s99KwOGWgb"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain-community\n",
        "!pip install -U -q langchain_core\n",
        "!pip install -U -q gigachain-community\n",
        "!pip install -U -q pypdf\n",
        "!pip install -U -q chromadb\n",
        "!pip install -U -q tiktoken\n",
        "!pip install -U -q langchain_experimental\n",
        "!pip install -U -q rank_bm25\n",
        "!pip install -U -q rouge\n",
        "!pip install -U -q transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/main/dataset/clean/requirements.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/main/dataset/clean/risk1.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/main/dataset/clean/risk2.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/luzanin/dataset/data_for_pipeline/queries1.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/luzanin/dataset/data_for_pipeline/queries2.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/luzanin/dataset/data_for_pipeline/queries3.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/luzanin/dataset/data_for_pipeline/end_to_end.csv\n",
        "!wget -q https://raw.githubusercontent.com/artyomrabosh/rag_for_sber/refs/heads/aandreev/validation_generation.py"
      ],
      "metadata": {
        "id": "kFKUJMwHfTTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYRNytTDFIps"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "import langchain_core\n",
        "from langchain_core.documents.base import Document\n",
        "from langchain.vectorstores import Chroma\n",
        "import langchain\n",
        "from langchain.chat_models import gigachat\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "from langchain.chat_models.gigachat import GigaChat\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "import nltk\n",
        "from nltk import WordPunctTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "\n",
        "import chromadb\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "from google.colab import userdata\n",
        "API_TOKEN = userdata.get('GIGACHAT')\n",
        "\n",
        "\n",
        "from retrieval_modules import *\n",
        "from retriever_validation import *\n",
        "from validation_generation import *\n",
        "\n",
        "from langchain.text_splitter import (RecursiveCharacterTextSplitter,\n",
        "                                    SentenceTransformersTokenTextSplitter,\n",
        "                                    TokenTextSplitter,\n",
        "                                    NLTKTextSplitter,\n",
        "                                    SpacyTextSplitter\n",
        "                                    )\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx-mR3QIq9vv"
      },
      "outputs": [],
      "source": [
        "# from sentence_transformers import CrossEncoder\n",
        "\n",
        "# reranker_model = CrossEncoder('DiTy/cross-encoder-russian-msmarco', max_length=512, device='cuda')\n",
        "\n",
        "# from sentence_transformers import SentenceTransformer\n",
        "# model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
        "# embeddings_1 = model.encode(sentences_1, normalize_embeddings=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42zjTBToqbDm"
      },
      "outputs": [],
      "source": [
        "class Embedder_wrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def embed_documents(self, texts):\n",
        "        return [self.model.encode(text) for text in texts]\n",
        "\n",
        "    def embed_docs_pc(self, docs):\n",
        "        return [self.model.encode(doc.page_content) for doc in docs]\n",
        "\n",
        "    def embed_query(self, query):\n",
        "        return self.model.encode(query)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\").to(device)\n",
        "embedder = Embedder_wrapper(model)\n",
        "\n",
        "clear_output(wait=True)\n"
      ],
      "metadata": {
        "id": "GIt1gYRLNSWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSI5hBPMWzom"
      },
      "source": [
        "##### Скачивамем обработанные документы"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_1 = pd.read_csv('risk1.csv')\n",
        "document_2 = pd.read_csv('risk2.csv')\n",
        "document_3 = pd.read_csv('requirements.csv')"
      ],
      "metadata": {
        "id": "ZqvW19qw1QnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_1 = []\n",
        "docs_2 = []\n",
        "docs_3 = []\n",
        "for row in document_1.iterrows():\n",
        "    docs_1.append(Document(row[1].loc['content']))\n",
        "    docs_1[-1].metadata = {'header_1': row[1].loc['Header_1'],\n",
        "                           'header_2': row[1].loc['Header_2'],\n",
        "                           'header_3': row[1].loc['Header_3']}\n",
        "\n",
        "for row in document_2.iterrows():\n",
        "    docs_2.append(Document(row[1].loc['content']))\n",
        "    docs_2[-1].metadata = {'header_1': row[1].loc['Header_1'],\n",
        "                           'header_2': row[1].loc['Header_2'],\n",
        "                           'header_3': row[1].loc['Header_3']}\n",
        "\n",
        "for row in document_3.iterrows():\n",
        "    docs_3.append(Document(row[1].loc['content']))\n",
        "    docs_3[-1].metadata = {'header_1': row[1].loc['Header_1'],\n",
        "                           'header_2': row[1].loc['Header_2'],\n",
        "                           'header_3': row[1].loc['Header_3']}\n"
      ],
      "metadata": {
        "id": "bdCCvY0F1dbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "whole_doc = docs_1 + docs_2 + docs_3"
      ],
      "metadata": {
        "id": "YM5BOTXr2h3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# данный сплиттер с этими параметрами был выбран после валидации ретривера\n",
        "\n",
        "splitter = SpacyTextSplitter(chunk_overlap=100, chunk_size=1024)\n",
        "splitted_docs = splitter.split_documents(whole_doc)\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splitted_docs,\n",
        "    embedding=embedder,\n",
        "    persist_directory=f'docs/'\n",
        ")\n",
        "\n",
        "clear_output(wait=True)"
      ],
      "metadata": {
        "id": "7lXPl5wMNxI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL1hufKR71lC"
      },
      "source": [
        "##### Загружаем датасет с вопросами"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries_1 = pd.read_csv('queries1.csv')\n",
        "queries_2 = pd.read_csv('queries2.csv')\n",
        "queries_3 = pd.read_csv('queries3.csv')\n",
        "end_to_end = pd.read_csv('end_to_end.csv')\n",
        "\n",
        "all_queries = pd.concat([queries_1[['Вопрос', 'Ответ']],\n",
        "                         queries_2[['Вопрос', 'Ответ']],\n",
        "                         queries_3[['Вопрос', 'Ответ']],\n",
        "                         end_to_end[['Вопрос', 'Ответ']]])"
      ],
      "metadata": {
        "id": "Nlxl1VFOm0RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### End-to-end Валидация"
      ],
      "metadata": {
        "id": "BN6bnokhNBnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'db' : vectordb, 'strategy' : 'ss', 'fusion_alpha' : 0.6}\n",
        "retriever = Retriever(**param)"
      ],
      "metadata": {
        "id": "NIk2NiQ5CrWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "giga_chat = GigaChat(credentials=API_TOKEN, verify_ssl_certs=False)\n",
        "\n",
        "rag = RAG(retriever, giga_chat)\n",
        "\n",
        "tp = \"\"\"Используй данный контест чтобы ответить на вопрос в конце. Для ответа используй не более двух предложений.\\\n",
        "```{information}```\n",
        "Вопрос: {query}\n",
        "Ответ:\"\"\"\n",
        "\n",
        "all_queries['gpt4o'] = all_queries['Вопрос'].apply(lambda x: rag.get_answer(x, tp)[0])\n"
      ],
      "metadata": {
        "id": "Ey3YtNv7PEYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = {\n",
        "    'Вопрос' : 'question',\n",
        "    'Ответ' : 'golden_answer',\n",
        "     'gpt4o' : 'rag_answer',\n",
        "    # 'context_chunks': 'chunks'  # TODO\n",
        "}\n",
        "all_queries = all_queries.rename(columns = columns)"
      ],
      "metadata": {
        "id": "rEO0ZdMYH0z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GigaChat(\n",
        "    credentials=API_TOKEN,\n",
        "    scope=\"GIGACHAT_API_PERS\",\n",
        "    model=[\"GigaChat\", \"GigaChat-Pro\"][0],\n",
        "    # Отключает проверку наличия сертификатов НУЦ Минцифры\n",
        "    verify_ssl_certs=False,\n",
        ")\n",
        "\n",
        "model.invoke('say something').content\n"
      ],
      "metadata": {
        "id": "v9F95wW2EZbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics = calculate_generation_metrics_v1(all_queries, model)\n",
        "df_metrics.head()\n"
      ],
      "metadata": {
        "id": "VgjClO1dId3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_metrics.drop(columns=['question', 'golden_answer', 'rag_answer', 'llm_score1_desc']).mean(axis=0)\n"
      ],
      "metadata": {
        "id": "TZoDcQs1IiOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pripd8L7bGpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVNQKArabGg-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}