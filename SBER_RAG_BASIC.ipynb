{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6s99KwOGWgb"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain-community\n",
    "!pip install -q langchain_core\n",
    "!pip install -q gigachain-community\n",
    "!pip install -q pypdf\n",
    "!pip install -q chromadb\n",
    "!pip install -q tiktoken\n",
    "!pip install -q langchain_experimental\n",
    "!pip install -q rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nYRNytTDFIps"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import langchain_core\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "\n",
    "document_1 = PyPDFLoader(\"Положение-Банка-России-от-30-января-2023-г-N-814-П-О-порядке-расчета-размера-опе.pdf\").load()\n",
    "document_2 = PyPDFLoader(\"Положение-Банка-России-от-7-декабря-2020-г-N-744-П-О-порядке-расчета-размера-опе.pdf\").load()\n",
    "document_3 = PyPDFLoader(\"Положение-Банка-России-от-8-апреля-2020-г-N-716-П-О-требованиях-к-системе-управл.pdf\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSI5hBPMWzom"
   },
   "source": [
    "##### Для начала будем обрабатывать документ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAEgOyH_YYy0"
   },
   "outputs": [],
   "source": [
    "# чистим от колонтитулов\n",
    "\n",
    "all_document = ''.join([document_3[i].page_content for i in range(len(document_3))])\n",
    "print('lenght before cleaning:', len(all_document))\n",
    "spam = 'Положение Банка России от 8 апреля 2020 г. N 716-П \"О требованиях к системе управления операционным риском… \\n10.11.2024  Система ГАРАНТ '\n",
    "all_document = ''.join([chunk for chunk in all_document.split(spam)])\n",
    "print('lenght after cleaning:', len(all_document))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYFveDhxFLwe"
   },
   "outputs": [],
   "source": [
    "# делим на главы и приложения\n",
    "chapters = all_document.split('Глава ')[1:]\n",
    "applications = chapters[-1].split('Приложение ')[1:]\n",
    "chapters[-1] = chapters[-1].split('Приложение ')[0]\n",
    "\n",
    "whole_doc_dirty = all_document.replace('\\n', '')\n",
    "\n",
    "# делим на пункты\n",
    "chapters = [re.split('(?:\\d\\.)+ ', chapter)[1:] for chapter in chapters][:-1]\n",
    "\n",
    "# chapters = [[chunk for chunk in chapter if len(chunk) > 100] for chapter in chapters]\n",
    "applications = [re.split('(?:\\d\\.)+ ', application)[1:] for application in applications][:-1]\n",
    "# applications = [[chunk for chunk in chapter if len(chunk) > 100] for chapter in applications]\n",
    "\n",
    "\n",
    "# # объединям все части\n",
    "whole_doc = [Document(punkt.replace('\\n', '')) for chapter in chapters + applications for punkt in chapter]\n",
    "whole_doc = [doc for doc in whole_doc if len(doc.page_content) > 100]\n",
    "print('число пунктов в документе:', len(whole_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CMBeAEKxRDI"
   },
   "outputs": [],
   "source": [
    "def find_number(chunk):\n",
    "    prefix = whole_doc_dirty.split(chunk)[0]\n",
    "    return re.findall('(?:\\d+\\.)+ ', prefix)[-1][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeynaUK_xNl2"
   },
   "outputs": [],
   "source": [
    "for doc in whole_doc:\n",
    "    doc.metadata = {'header_2':find_number(doc.page_content)}\n",
    "\n",
    "whole_doc[0].metadata['header_1'] = 1\n",
    "header = 1\n",
    "for i, doc in enumerate(whole_doc[1:]):\n",
    "    if doc.metadata['header_2'][0] != whole_doc[i].metadata['header_2'][0]:\n",
    "        header += 1\n",
    "    doc.metadata['header_1'] = header\n",
    "\n",
    "\n",
    "big_chapter_doc = []\n",
    "current_header = 1\n",
    "current_page_content = ''\n",
    "for doc in whole_doc:\n",
    "    if doc.metadata['header_1'] == current_header:\n",
    "        current_page_content += doc.page_content\n",
    "    else:\n",
    "        new_doc = Document(current_page_content)\n",
    "        new_doc.metadata = {'header':current_header}\n",
    "        big_chapter_doc.append(new_doc)\n",
    "        current_page_content = doc.page_content\n",
    "        current_header += 1\n",
    "\n",
    "new_doc = Document(current_page_content)\n",
    "new_doc.metadata = {'header':current_header}\n",
    "big_chapter_doc.append(new_doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL8BFHNTtjEl"
   },
   "source": [
    "##### GigaChat API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_WD8Pf4MdnR"
   },
   "source": [
    "##### Разбиение на чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWJcuNNz7nZt"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YRDgXVylNCSX"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (RecursiveCharacterTextSplitter,\n",
    "                                    SentenceTransformersTokenTextSplitter,\n",
    "                                    TokenTextSplitter,\n",
    "                                    NLTKTextSplitter,\n",
    "                                    SpacyTextSplitter\n",
    "                                    )\n",
    "\n",
    "TOKENS_PER_CHUNK_SIZE = 256\n",
    "CHUNK_OVERLAP = 0\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=CHUNK_OVERLAP, tokens_per_chunk=TOKENS_PER_CHUNK_SIZE)\n",
    "\n",
    "splitted_docs = token_splitter.split_documents(whole_doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O6CzgBHJEyOx"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from google.colab import userdata\n",
    "\n",
    "LLAMA_TOKEN = userdata.get('LLAMA')\n",
    "\n",
    "\n",
    "def llama_responce(prompt):\n",
    "    client = OpenAI(\n",
    "        base_url=\"https://openrouter.ai/api/v1\",\n",
    "        api_key=LLAMA_TOKEN,\n",
    "    )\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.1-70b-instruct:free\",\n",
    "        messages=[\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeBo_mN8W5qh"
   },
   "source": [
    "##### Contextual Chunk Headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW_L5jFoH_VU"
   },
   "outputs": [],
   "source": [
    "# тут нужно выбрать более стабильный API и более хорошую модель для суммаризации\n",
    "summaries = []\n",
    "\n",
    "# for doc in whole_doc:\n",
    "#     prompt = \"Отвечай как юрист в банковской сфере. Ответ должен содержать не больше 5 предложений. Приведи суммаризацию данного текста.\\nТекст: \"\\\n",
    "#     + doc.page_content\n",
    "#     new_doc = Document(llama_responce(prompt))\n",
    "#     new_doc.metadata = doc.metadata\n",
    "#     summaries.append(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AtBKsauXIN7"
   },
   "source": [
    "##### Document Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueajLXY9TwS6"
   },
   "outputs": [],
   "source": [
    "# тут нужно выбрать более стабильный API\n",
    "\n",
    "enriched_docs = []\n",
    "\n",
    "# for doc in whole_doc:\n",
    "#     prompt = \"Отвечай как юрист в банковской сфере. Приведи пример двух вопросов, которые можно задать по заданному тексту.\\nТекст: \"\\\n",
    "#     + doc.page_content\n",
    "#     new_doc = Document(llama_responce(prompt))\n",
    "#     new_doc.metadata = doc.metadata\n",
    "#     enriched_docs.append(new_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC_J6YNETGSs"
   },
   "source": [
    "##### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbDNwgfmTIyE"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "import langchain\n",
    "\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5uqSEaQQTIvv"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# model = SentenceTransformer(\"deepvk/USER-bge-m3\")\n",
    "# model = SentenceTransformer(\"intfloat/multilingual-e5-large\").to('cuda')\n",
    "model = SentenceTransformer(\"intfloat/multilingual-e5-large-instruct\").to('cuda')\n",
    "# model = SentenceTransformer(\"BAAI/bge-m3\").to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42zjTBToqbDm"
   },
   "outputs": [],
   "source": [
    "class Embedder_wrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self.model.encode(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, query):\n",
    "        return self.model.encode(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ujPK9INqxow"
   },
   "outputs": [],
   "source": [
    "embedder = Embedder_wrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGAIp_UeadMw"
   },
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    embedding=embedder,\n",
    "    persist_directory='docs/chroma2/'\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0FPGK8QNzi68"
   },
   "outputs": [],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL1hufKR71lC"
   },
   "source": [
    "##### Загружаем датасет с вопросами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4H2tikqiJ6ao"
   },
   "outputs": [],
   "source": [
    "query_answer = pd.read_excel('queries2.xlsx')\n",
    "query_answer = query_answer.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "queries = list(query_answer['Вопрос'])\n",
    "answers = list(query_answer['Ответ'])\n",
    "punkts = [re.findall(r'(?:\\d+\\.)*\\d+', answer) for query, answer in zip(queries, answers)]\n",
    "queries_df = pd.DataFrame({'query': queries, 'answer' : answers, 'punkts': punkts})\n",
    "queries_df = queries_df[queries_df['punkts'].apply(lambda x: len(x) == 2)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "775bYJ_4VhwO"
   },
   "source": [
    "##### Считаем метрики для поиска чанка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaTunISqiuij"
   },
   "outputs": [],
   "source": [
    "def print_metrics_dummy(queries, query_column_name='query', max_ = 10, min_ = 3):\n",
    "    for k in range(min_, max_+1):\n",
    "        right = 0\n",
    "        all = len(queries) * 2\n",
    "        for row in queries.iterrows():\n",
    "            right_answers = row[1].loc['punkts']\n",
    "            query = row[1].loc[query_column_name]\n",
    "            res = []\n",
    "            ss = vectordb.max_marginal_relevance_search(query, k)\n",
    "\n",
    "            for doc in ss:\n",
    "                res.append(doc.metadata['header'])\n",
    "            for answer in right_answers:\n",
    "                if answer + '.' in res:\n",
    "                    right += 1\n",
    "\n",
    "        print(f'Recall@{k} =', right / all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "\n",
    "from google.colab import userdata\n",
    "API_TOKEN = userdata.get('GIGACHAT')\n",
    "\n",
    "giga_chat = GigaChat(credentials=API_TOKEN, verify_ssl_certs=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pj89Z4ZUgoPn"
   },
   "source": [
    "#### Fusion Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMRoFTHkgxvG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk import WordPunctTokenizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def clean_text(text):\n",
    "    text = WordPunctTokenizer().tokenize(text)\n",
    "    text = [token.lower() for token in text if token.isalpha() and token not in russian_stopwords]\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEVpVZWZg4hy"
   },
   "outputs": [],
   "source": [
    "def fusion_retrieval_block(db, query, alpha=0.9, top_k=10):\n",
    "\n",
    "    db_retrieved_scores = db.similarity_search_with_relevance_scores(query, len(db))\n",
    "\n",
    "    clean_texts = [clean_text(doc[0].page_content) for doc in db_retrieved_scores]\n",
    "    BMdb = BM25Okapi(clean_texts)\n",
    "\n",
    "    bm25_scores = BMdb.get_scores(clean_text(query))\n",
    "\n",
    "    vector_scores = np.array([score for _, score in db_retrieved_scores])\n",
    "    vector_scores = 1 - (vector_scores - np.min(vector_scores)) / (np.max(vector_scores) - np.min(vector_scores))\n",
    "\n",
    "    bm25_scores = (bm25_scores - np.min(bm25_scores)) / (np.max(bm25_scores) - np.min(bm25_scores))\n",
    "\n",
    "    combined_scores = alpha * vector_scores + (1 - alpha) * bm25_scores\n",
    "\n",
    "    sorted_indices = np.argsort(combined_scores)[::-1]\n",
    "\n",
    "    return [db_retrieved_scores[i] for i in sorted_indices[:top_k]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfzIngzRpalY"
   },
   "source": [
    "#### Rerankers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6ygjRuNqy9w"
   },
   "source": [
    "##### LLM reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhlOMyc6pMQs"
   },
   "outputs": [],
   "source": [
    "def llm_ranker(query, answers, model=giga_chat):\n",
    "\n",
    "    MODEL_INSTRUCTION = 'Ты юрист в банковской сфере. Отвечай на вопросы на основе Положения Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"'\n",
    "\n",
    "    template = \"\"\"Ответ должен содержать ровно одно число. Оцени по шкале от 1 до 10, насколько хорошо данный ответ отвечает на заданный вопрос.\\\n",
    "Вопрос: {query}\\\n",
    "Ответ: {answer}\"\"\"\n",
    "    prompt = PromptTemplate(template=template, input_variables=['query', 'answer'])\n",
    "    scores = []\n",
    "    for answer in answers:\n",
    "        PROMPT = prompt.format(query=query, answer=answer.page_content)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=MODEL_INSTRUCTION\n",
    "            ),\n",
    "            HumanMessage(content=PROMPT)\n",
    "        ]\n",
    "        scores.append(float(model(messages)))\n",
    "\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gx4HEfAPq6sr"
   },
   "source": [
    "##### Cross encoder msmacro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lx-mR3QIq9vv"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "reranker_model = CrossEncoder('DiTy/cross-encoder-russian-msmarco', max_length=512, device='cuda')\n",
    "def cross_encoder_ranker(query, answers):\n",
    "    answers = [answer.page_content for answer in answers]\n",
    "    rank_result = reranker_model.rank(query, answers)\n",
    "    vals = [res['score'] for res in rank_result]\n",
    "    return vals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fd84DexvhVny"
   },
   "source": [
    "#### Rerancer BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WxtVwI3ChYEi"
   },
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# model = SentenceTransformer('BAAI/bge-large-zh-v1.5')\n",
    "# embeddings_1 = model.encode(sentences_1, normalize_embeddings=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CI5s7YvtFt2S"
   },
   "source": [
    "#### RSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXyKEsIeFwz8"
   },
   "source": [
    "Идея: складываем скоры в каком-то окне вокруг чанка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YD2b2eAwF3vK"
   },
   "outputs": [],
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T-JRb-X4xGp"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0jyolg65Iqr"
   },
   "outputs": [],
   "source": [
    "def chat(model, prompt):\n",
    "    MODEL_INSTRUCTION = 'Ты юрист в банковской сфере. Отвечай на вопросы на основе Положения Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"'\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=MODEL_INSTRUCTION\n",
    "        ),\n",
    "        HumanMessage(content=prompt)\n",
    "    ]\n",
    "\n",
    "    res = model(messages)\n",
    "    return res.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1fCjIt94zax"
   },
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, db, reranker=None, strategy='mmr', fusion_alpha=1, k = 10, has_answer_th = 0.):\n",
    "        self.database = db\n",
    "        self.reranker = reranker\n",
    "        self.strategy = strategy\n",
    "        self.fusion_alpha = fusion_alpha\n",
    "        self.k = k\n",
    "        self.has_answer_th = has_answer_th\n",
    "\n",
    "    def rerank_docs(self, query, docs):\n",
    "        if self.reranker is None:\n",
    "            return np.zeros(len(docs))\n",
    "        return self.reranker(query, docs)\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        query = self.get_advance_query(query)\n",
    "        if self.strategy == 'mmr':\n",
    "            docs = self.database.max_marginal_relevance_search(query, self.k)\n",
    "            scores = self.rerank_docs(query, docs)\n",
    "\n",
    "        else:\n",
    "            docs, fusion_scores = fusion_retrieval_block(self.database, query, self.fusion_alpha, self.k)\n",
    "            reranker_scores = self.rerank_docs(docs)\n",
    "            scores = reranker_scores + fusion_scores\n",
    "\n",
    "        score_doc = list(zip(scores, docs))\n",
    "        score_doc.sort(key=lambda x: x[0])\n",
    "        if score_doc[0][0] < self.has_answer_th:\n",
    "            return None\n",
    "        return [elem[1] for elem in score_doc]\n",
    "\n",
    "    def get_advance_query(self, query): # оболочка для продвинутого класса\n",
    "        return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GlrQFoJV5XDX"
   },
   "outputs": [],
   "source": [
    "class EnrichAsAnswerRetriever(Retriever):\n",
    "    def __init__(self, db, reranker=None, chat_model=None):\n",
    "        super().__init__(db, reranker)\n",
    "        self.chat_model = chat_model\n",
    "\n",
    "    def get_advance_query(self, query):\n",
    "        PROMPT = 'Приведи пример ответа, который можно найти в Положении Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"\\n\\\n",
    "Вопрос: Расскажи про учет изменений в иностранном законодательстве при управлении оп риском в зарубежных дочерних кредитных организациях?\\n\\\n",
    "Ответ: Кредитная организация должна учитывать требования национального законодательства иностранного государства при управлении операционным риском в дочерних организациях, включая порог регистрации событий. При этом показатели операционного риска приводятся в соответствие с требованиями национального законодательства, если оно противоречит требованиям Положения.\\n\\\n",
    "Вопрос: Как кредитная организация должна учитывать потери от реализации событий операционного риска при расчете капитала, и какие требования предъявляются к ведению базы событий в этом контексте?\\n\\\n",
    "Ответ: Кредитная организация должна ежемесячно определять величину валовых потерь от реализации событий операционного риска и использовать эти данные при выборе подхода к расчету объема капитала на покрытие таких потерь, выбирая между регуляторным и продвинутым подходами.\\n\\\n",
    "Вопрос: '\n",
    "\n",
    "        new_prompt = PROMPT + query + '\\nОтвет: '\n",
    "        return query + '\\n' + chat(self.chat_model, new_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqdDNVZTDK_t"
   },
   "outputs": [],
   "source": [
    "class EnrichAsQueryRetriever(Retriever):\n",
    "    def __init__(self, db, reranker=None, chat_model=None, query_count=3):\n",
    "        super().__init__(db, reranker)\n",
    "        self.chat_model = chat_model\n",
    "        self.query_count = query_count\n",
    "\n",
    "    def get_advance_query(self, query):\n",
    "        PROMPT = f'Переформулируй вопрос {self.query_count} способами таким образом, чтобы ответ на них можно было найти в \\\n",
    "Положении Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"\\n \\\n",
    "Вопрос: '\n",
    "\n",
    "        new_prompt = PROMPT + query\n",
    "        return query + '\\n' + chat(self.chat_model, new_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAPi1FWv_qLi"
   },
   "outputs": [],
   "source": [
    "class EnrichAsCorrectionRetriever(Retriever):\n",
    "    def __init__(self, db, reranker=None, chat_model=None, query_count=3):\n",
    "        super().__init__(db, reranker)\n",
    "        self.chat_model = chat_model\n",
    "        self.query_count = query_count\n",
    "\n",
    "    def get_advance_query(self, query):\n",
    "        PROMPT = f'Ответь одним предложением.\\nПереформулируй вопрос так, чтобы он стал более детальным и конкретным. Ответ на вопрос можно найти в \\\n",
    "Положении Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"\\n \\\n",
    "Вопрос: '\n",
    "\n",
    "        new_prompt = PROMPT + query\n",
    "        return query + '\\n' + chat(self.chat_model, new_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORDDnMT-_tWn"
   },
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    def __init__(self, retriever, model, verbose = False):\n",
    "        self.chat_model = model\n",
    "        self.retriever = retriever\n",
    "\n",
    "\n",
    "    def get_answer(self, query, template):\n",
    "\n",
    "        retrieved_documents = self.retriever.retrieve(query)\n",
    "        if retrieved_documents is None:\n",
    "            return 'Нет подходящей информации в данном документе'\n",
    "        docs_page_content = [doc.page_content for doc in retrieved_documents]\n",
    "        information = \"\\n\\n\".join(docs_page_content)\n",
    "        prompt = PromptTemplate(template=template[0], input_variables=['information', 'query'])\n",
    "\n",
    "        answer = chat(self.chat_model, prompt.format(information=information, query=query))\n",
    "        return answer, retrieved_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xE84EXVNaIrj"
   },
   "outputs": [],
   "source": [
    "retriever = EnrichAsCorrectionRetriever(vectordb, reranker=cross_encoder_ranker, chat_model=giga_chat)\n",
    "rag = RAG(retriever, giga_chat)\n",
    "\n",
    "tp = \"\"\"Используй данный контест чтобы ответить на вопрос в конце. Для ответа используй не более двух предложений.\\\n",
    "```{information}```\n",
    "Вопрос: {query}\n",
    "Ответ:\"\"\"\n",
    "\n",
    "rag.get_answer(queries[0], tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXrlv6oZimcT"
   },
   "outputs": [],
   "source": [
    "def measure_function(query, answer, model, is_chat=True):\n",
    "    if is_chat:\n",
    "\n",
    "        MODEL_INSTRUCTION = 'Ты юрист в банковской сфере. Отвечай на вопросы на основе Положения Банка России \\\n",
    "\"О требованиях к системе управления операционным риском в кредитной организации \\\n",
    "и банковской группе.\"'\n",
    "\n",
    "        template = \"\"\"Ответ должен содержать ровно одно число. Оцени по шкале от 1 до 100, насколько хорошо данный ответ отвечает на заданный вопрос.\\\n",
    "Вопрос: {query}\\\n",
    "Ответ: {answer}\"\"\"\n",
    "        prompt = PromptTemplate(template=template, input_variables=['query', 'answer'])\n",
    "\n",
    "        PROMPT = prompt.format(query=query, answer=answer)\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=MODEL_INSTRUCTION\n",
    "            ),\n",
    "            HumanMessage(content=PROMPT)\n",
    "        ]\n",
    "\n",
    "        res = model(messages)\n",
    "        return res.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-H0jzRUgn8A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
